---
phase: 05-time-series
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - bindings/python/src/quiver/_c_api.py
  - bindings/python/src/quiver/database.py
  - bindings/python/tests/conftest.py
  - bindings/python/tests/test_database_time_series.py
autonomous: true
requirements: [TS-01, TS-02]
must_haves:
  truths:
    - "read_time_series_group returns a list of row dicts with correct Python types per column (int for INTEGER, float for FLOAT, str for STRING/DATE_TIME)"
    - "update_time_series_group persists rows correctly and round-trips through read"
    - "update_time_series_group with empty list clears all rows for that element"
    - "Both read and update raise errors for nonexistent elements (C API errors propagate)"
  artifacts:
    - path: "bindings/python/src/quiver/_c_api.py"
      provides: "CFFI cdef declarations for all 10 time series C API functions"
      contains: "quiver_database_read_time_series_group"
    - path: "bindings/python/src/quiver/database.py"
      provides: "read_time_series_group and update_time_series_group methods"
      contains: "def read_time_series_group"
    - path: "bindings/python/tests/test_database_time_series.py"
      provides: "Time series group read/write/clear tests"
      contains: "test_read_time_series_group"
  key_links:
    - from: "bindings/python/src/quiver/database.py"
      to: "quiver_database_read_time_series_group"
      via: "CFFI lib call with void** output casting"
      pattern: "quiver_database_read_time_series_group"
    - from: "bindings/python/src/quiver/database.py"
      to: "quiver_database_update_time_series_group"
      via: "CFFI lib call with keepalive columnar arrays"
      pattern: "quiver_database_update_time_series_group"
    - from: "bindings/python/src/quiver/database.py"
      to: "quiver_database_free_time_series_data"
      via: "try/finally cleanup of read results"
      pattern: "free_time_series_data"
---

<objective>
Add CFFI declarations for all time series C API functions, implement `read_time_series_group` and `update_time_series_group` methods on the Database class, and add tests using the mixed_time_series schema.

Purpose: TS-01 and TS-02 are the most complex operations in Phase 5, requiring void** columnar dispatch by type for reads and columnar typed-array marshaling with keepalive for writes. Completing these first establishes the pattern for the simpler files operations.

Output: Two new Database methods, CFFI declarations for all 10 time series functions (group + files + free), test fixtures for both schemas, and a new test file covering group read/write/clear.
</objective>

<execution_context>
@C:/Users/rsampaio/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/rsampaio/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-time-series/05-CONTEXT.md
@.planning/phases/05-time-series/05-RESEARCH.md
@bindings/python/src/quiver/_c_api.py
@bindings/python/src/quiver/database.py
@bindings/python/tests/conftest.py
@include/quiver/c/database.h
@tests/schemas/valid/mixed_time_series.sql
@tests/schemas/valid/collections.sql
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add CFFI declarations and implement read/update time series group</name>
  <files>
    bindings/python/src/quiver/_c_api.py
    bindings/python/src/quiver/database.py
  </files>
  <action>
**1. Add CFFI cdef declarations** to `_c_api.py` (append inside the existing `ffi.cdef("""...""")` block, before the closing `"""`):

Add all 10 time series C API functions. Use `void**` (not `const void* const*`) for `column_data` in `update_time_series_group` per Phase 4 decision about CFFI ABI-mode ignoring const qualifiers:

```c
// Time series group read/update/free
quiver_error_t quiver_database_read_time_series_group(quiver_database_t* db,
    const char* collection, const char* group, int64_t id,
    char*** out_column_names, int** out_column_types,
    void*** out_column_data, size_t* out_column_count, size_t* out_row_count);

quiver_error_t quiver_database_update_time_series_group(quiver_database_t* db,
    const char* collection, const char* group, int64_t id,
    const char* const* column_names, const int* column_types,
    void** column_data, size_t column_count, size_t row_count);

quiver_error_t quiver_database_free_time_series_data(char** column_names,
    int* column_types, void** column_data,
    size_t column_count, size_t row_count);

// Time series files
quiver_error_t quiver_database_has_time_series_files(quiver_database_t* db,
    const char* collection, int* out_result);

quiver_error_t quiver_database_list_time_series_files_columns(quiver_database_t* db,
    const char* collection, char*** out_columns, size_t* out_count);

quiver_error_t quiver_database_read_time_series_files(quiver_database_t* db,
    const char* collection, char*** out_columns, char*** out_paths, size_t* out_count);

quiver_error_t quiver_database_update_time_series_files(quiver_database_t* db,
    const char* collection, const char* const* columns, const char* const* paths,
    size_t count);

quiver_error_t quiver_database_free_time_series_files(char** columns, char** paths, size_t count);
```

**2. Add `read_time_series_group` method** to `database.py` on the Database class, after the `list_time_series_groups` method:

- Signature: `def read_time_series_group(self, collection: str, group: str, id: int) -> list[dict]:`
- Parameter order follows C++ / C API: `(collection, group, id)` -- NOT `(collection, id, group)`
- Allocate out-params: `char***`, `int**`, `void***`, `size_t*`, `size_t*`
- Call `quiver_database_read_time_series_group` via `check()`
- If `col_count == 0 or row_count == 0`, return `[]`
- In `try` block: iterate columns, read names and types, then transpose columnar to row dicts:
  - Type 0 (INTEGER): `ffi.cast("int64_t*", out_data[0][c])[r]` -- value is Python int
  - Type 1 (FLOAT): `ffi.cast("double*", out_data[0][c])[r]` -- value is Python float
  - Type 2 (STRING) or 3 (DATE_TIME): `ffi.string(ffi.cast("char**", out_data[0][c])[r]).decode("utf-8")` -- value is Python str
  - Per CONTEXT.md and research discretion: DATE_TIME columns return plain `str`, no auto-parsing
- In `finally` block: call `quiver_database_free_time_series_data(out_names[0], out_types[0], out_data[0], col_count, row_count)`

**3. Add `_marshal_time_series_columns` module-level helper** to `database.py`, after `_marshal_params`:

- Signature: `def _marshal_time_series_columns(rows: list[dict], metadata: GroupMetadata) -> tuple:`
- Returns `(keepalive, c_col_names, c_col_types, c_col_data, col_count, row_count)`
- Build column schema from metadata: dimension column first (type is STRING=2 since dimension is always TEXT), then each `value_columns` entry with its `data_type`
- Validate every row dict has all required column names -- raise `ValueError(f"Row {r} is missing column '{name}'")` if any missing
- Validate strict types per CONTEXT.md:
  - INTEGER column: value must be `int` (not bool) -- raise `TypeError(f"Column '{name}' expects int, got {type(v).__name__}")`
  - FLOAT column: value must be `float` -- raise `TypeError(f"Column '{name}' expects float, got {type(v).__name__}")`
  - STRING/DATE_TIME column: value must be `str` -- raise `TypeError(f"Column '{name}' expects str, got {type(v).__name__}")`
  - Note: `bool` is a subclass of `int` in Python. Use `type(v) is int` (not `isinstance`) for INTEGER check to reject bools.
- Transpose rows to columnar arrays using `ffi.new` with keepalive pattern (same as `_marshal_params`):
  - For INTEGER: `ffi.new("int64_t[]", [row[name] for row in rows])`
  - For FLOAT: `ffi.new("double[]", [row[name] for row in rows])`
  - For STRING/DATE_TIME: encode each string, create `char[]` buffers, then `char*[]` array
  - Cast each array to `void*` and store in `ffi.new("void*[]", col_count)`
- Build `c_col_names = ffi.new("const char*[]", col_count)` with encoded name buffers (add to keepalive)
- Build `c_col_types = ffi.new("int[]", col_count)` with type integers

**4. Add `update_time_series_group` method** to `database.py` on the Database class, right after `read_time_series_group`:

- Signature: `def update_time_series_group(self, collection: str, group: str, id: int, rows: list[dict]) -> None:`
- If `rows` is empty: call C API with `ffi.NULL, ffi.NULL, ffi.NULL, 0, 0` (clear operation)
- Otherwise: call `self.get_time_series_metadata(collection, group)` to get schema, then call `_marshal_time_series_columns(rows, metadata)` to build columnar arrays, then call C API
  </action>
  <verify>
Run `python -c "from quiver._c_api import ffi, get_lib; lib = get_lib(); print('CFFI declarations loaded')"` from the bindings/python directory with build/bin on PATH to confirm declarations parse correctly.
  </verify>
  <done>
CFFI declarations for all 10 time series functions parse without error. `read_time_series_group` and `update_time_series_group` methods exist on Database with correct signatures. `_marshal_time_series_columns` helper exists as module-level function.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add test fixtures and time series group tests</name>
  <files>
    bindings/python/tests/conftest.py
    bindings/python/tests/test_database_time_series.py
  </files>
  <action>
**1. Add fixtures to `conftest.py`:**

Add two new schema path fixtures and two database fixtures for time series testing:

```python
@pytest.fixture
def mixed_time_series_schema_path(schemas_path: Path) -> Path:
    """Return the path to the mixed time series test schema."""
    return schemas_path / "valid" / "mixed_time_series.sql"

@pytest.fixture
def mixed_time_series_db(mixed_time_series_schema_path: Path, tmp_path: Path) -> Generator[Database, None, None]:
    """Create a test database with the mixed time series schema (multi-type columns)."""
    database = Database.from_schema(str(tmp_path / "mixed_ts.db"), str(mixed_time_series_schema_path))
    yield database
    database.close()
```

The `collections_db` fixture already exists and uses `collections.sql` which has a single-column time series (`Collection_time_series_data` with `date_time` TEXT + `value` REAL) plus a `Collection_time_series_files` table.

**2. Create `test_database_time_series.py`** with comprehensive tests:

Use `mixed_time_series_db` for multi-column tests (Sensor schema: date_time TEXT, temperature REAL, humidity INTEGER, status TEXT) and `collections_db` for single-column + files tests.

Tests to write (cover all paths from research pitfalls):

**Read tests:**
- `test_read_time_series_group_empty` -- read from element with no rows returns `[]`
- `test_read_time_series_group_single_row` -- write one row, read back, verify all column types correct
- `test_read_time_series_group_multiple_rows` -- write multiple rows, read back, verify ordering and all values
- `test_read_time_series_group_column_order` -- verify dimension column (date_time) comes first in dict key order
- `test_read_time_series_group_types` -- verify int for INTEGER, float for FLOAT, str for STRING/DATE_TIME columns

**Write tests:**
- `test_update_time_series_group_round_trip` -- write rows, read back, assert exact match
- `test_update_time_series_group_clear` -- write rows, then update with `[]`, read back returns `[]`
- `test_update_time_series_group_overwrite` -- write rows, write different rows, read back returns only new rows

**Validation tests:**
- `test_update_time_series_group_missing_column` -- omit a column from row dict, expect ValueError
- `test_update_time_series_group_wrong_type_int_for_float` -- pass int where float expected, expect TypeError
- `test_update_time_series_group_wrong_type_str_for_int` -- pass str where int expected, expect TypeError
- `test_update_time_series_group_wrong_type_bool_for_int` -- pass bool where int expected, expect TypeError (strict type check)

**Single-column tests (using collections_db):**
- `test_read_time_series_group_single_column` -- write and read a simple date_time+value time series

For each test, create element first via `create_element` with a label, then use `update_time_series_group` to populate data before reading.

Test data for mixed_time_series_db (Sensor schema):
```python
rows = [
    {"date_time": "2024-01-01T00:00:00", "temperature": 20.5, "humidity": 65, "status": "normal"},
    {"date_time": "2024-01-02T00:00:00", "temperature": 21.3, "humidity": 70, "status": "normal"},
    {"date_time": "2024-01-03T00:00:00", "temperature": 19.8, "humidity": 55, "status": "low"},
]
```
  </action>
  <verify>
Run `bindings/python/test/test.bat` (or the equivalent pytest command with PATH including build/bin). All time series group tests pass.
  </verify>
  <done>
All time series group tests pass: read empty returns [], round-trip preserves values and types, clear via empty list works, overwrite replaces data, validation rejects missing columns and wrong types (including bool-as-int). Single-column time series also works.
  </done>
</task>

</tasks>

<verification>
1. CFFI declarations load without parse errors: `python -c "from quiver._c_api import ffi, get_lib; lib = get_lib()"`
2. All tests in `test_database_time_series.py` pass via `bindings/python/test/test.bat`
3. `read_time_series_group` returns `list[dict]` with correct Python types per column
4. `update_time_series_group` with empty list clears rows (returns `[]` on subsequent read)
5. Type validation rejects wrong types including bool-as-int
</verification>

<success_criteria>
- read_time_series_group returns correctly typed Python dicts (int/float/str per column type)
- update_time_series_group persists rows and round-trips correctly
- Empty list update clears all rows
- Strict type validation raises TypeError for wrong types, ValueError for missing columns
- All test_database_time_series.py tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/05-time-series/05-01-SUMMARY.md`
</output>
