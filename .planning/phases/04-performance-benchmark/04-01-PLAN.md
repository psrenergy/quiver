---
phase: 04-performance-benchmark
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/benchmark/benchmark.cpp
  - tests/CMakeLists.txt
  - scripts/build-all.bat
autonomous: true
requirements:
  - PERF-01

must_haves:
  truths:
    - "Running quiver_benchmark.exe prints a clean ASCII table comparing individual vs batched transaction performance"
    - "Batched variant completes measurably faster than individual variant on a file-based database"
    - "build-all.bat builds the benchmark executable but test-all.bat does NOT run it"
    - "Results show all four metrics: total time (ms), per-element time, ops/sec, speedup ratio"
    - "Header banner displays benchmark parameters (element count, time series rows per element, schema, iterations)"
  artifacts:
    - path: "tests/benchmark/benchmark.cpp"
      provides: "Standalone benchmark with two-variant comparison, statistics, and formatted output"
      min_lines: 150
    - path: "tests/CMakeLists.txt"
      provides: "quiver_benchmark target (no gtest_discover_tests)"
      contains: "quiver_benchmark"
    - path: "scripts/build-all.bat"
      provides: "Benchmark build step (no benchmark execution)"
  key_links:
    - from: "tests/benchmark/benchmark.cpp"
      to: "quiver::Database"
      via: "from_schema, create_element, update_time_series_group, begin_transaction, commit"
      pattern: "begin_transaction|create_element|update_time_series_group"
    - from: "tests/CMakeLists.txt"
      to: "tests/benchmark/benchmark.cpp"
      via: "add_executable target"
      pattern: "add_executable\\(quiver_benchmark"
---

<objective>
Create a standalone C++ benchmark executable that demonstrates measurable write throughput improvement from explicit transactions. The benchmark creates 5000 elements (each with scalars, vectors, and time series data) in two variants -- individual implicit transactions vs. a single wrapping explicit transaction -- runs 5 iterations per variant with a warm-up, computes median/mean statistics, and prints results in a clean ASCII table.

Purpose: Prove the performance motivation for explicit transactions is real and quantifiable.
Output: `build/bin/quiver_benchmark.exe` that prints comparison results to stdout.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-performance-benchmark/04-RESEARCH.md
@tests/schemas/valid/collections.sql
@tests/test_utils.h
@tests/CMakeLists.txt
@include/quiver/database.h
@include/quiver/element.h
@include/quiver/c/options.h
@scripts/build-all.bat
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create benchmark executable and CMake integration</name>
  <files>
    tests/benchmark/benchmark.cpp
    tests/CMakeLists.txt
  </files>
  <action>
Create `tests/benchmark/benchmark.cpp` as a standalone `main()` executable (no test framework). Include these standard headers: `<chrono>`, `<filesystem>`, `<algorithm>`, `<numeric>`, `<cstdio>`, `<string>`, `<vector>`, `<map>`. Include project headers: `<quiver/database.h>`, `<quiver/element.h>`, `<quiver/c/options.h>`. Also include `"../test_utils.h"` for schema path resolution.

**Constants:**
- `ELEMENT_COUNT = 5000`
- `TS_ROWS_PER_ELEMENT = 10`
- `ITERATIONS = 5` (plus 1 warm-up discarded)
- Schema path: use `quiver::test::path_from(__FILE__, "../schemas/valid/collections.sql")`

**Helper functions:**

1. `temp_db_path(suffix)` -- returns `(std::filesystem::temp_directory_path() / ("quiver_bench_" + suffix + ".db")).string()`

2. `make_element(int index)` -- builds Element with:
   - `label`: `"Item " + std::to_string(index)`
   - `some_integer`: `static_cast<int64_t>(index * 10)`
   - `some_float`: `static_cast<double>(index) * 1.1`
   - `value_int`: vector of 5 int64_t values `{index*1, index*2, ..., index*5}`
   - `value_float`: vector of 5 doubles `{index*0.1, index*0.2, ..., index*0.5}`

3. `make_time_series_rows(int element_index)` -- builds 10 rows with hourly timestamps starting from `"2024-01-01T00:00:00"`, `"2024-01-01T01:00:00"`, ..., `"2024-01-01T09:00:00"`. Each row has keys `"date_time"` (string) and `"value"` (double, computed as `(element_index * 10 + r) * 0.5`).

4. `Stats` struct with `median_ms`, `mean_ms`, `per_element_ms`, `ops_per_sec` fields (all double).

5. `compute_stats(std::vector<double>& times_ms, int element_count)` -- sorts the vector, computes median (middle element for odd count), mean via `std::accumulate`, per_element_ms = median / element_count, ops_per_sec = element_count / (median / 1000.0).

**Benchmark functions:**

6. `run_individual(schema_path, element_count)` -- creates a fresh temp DB via `Database::from_schema` with `{.read_only = 0, .console_level = QUIVER_LOG_OFF}`. Creates Configuration element (`label = "Default"`) outside the timed region. Times a loop of `element_count` iterations: `create_element("Collection", elem)` then `update_time_series_group("Collection", "data", id, rows)`. No explicit transaction wrapping -- each call uses its own implicit transaction via TransactionGuard. Returns elapsed time in milliseconds. Deletes the temp DB file after timing using `std::filesystem::remove`.

7. `run_batched(schema_path, element_count)` -- same as individual, but wraps the entire loop in `db.begin_transaction()` ... `db.commit()`. Returns elapsed time in milliseconds. Deletes the temp DB file after.

**Output functions:**

8. `print_results(individual_stats, batched_stats, element_count, ts_rows, iterations, schema_name)` -- prints:
   - Banner with `========` border, title "Quiver Transaction Benchmark"
   - Parameters: Elements, TS rows/elem, Schema (just the filename, not full path), Iterations
   - Table header: Variant | Total (ms) | Per-elem (ms) | Ops/sec | Speedup
   - Separator line of dashes
   - Row for "Individual" with speedup "1.00x"
   - Row for "Batched" with speedup = individual.median_ms / batched.median_ms, formatted as "Nx" with 2 decimal places
   - Use `printf` with `%-20s %12.1f %12.3f %12.1f %10s` style formatting for aligned columns

**main():**

- Print progress: `"Running warm-up: individual..."` then run 1 individual iteration (discard result)
- Print progress: `"Running warm-up: batched..."` then run 1 batched iteration (discard result)
- Collect `ITERATIONS` individual times, printing `"Running: individual [1/5]..."` etc.
- Collect `ITERATIONS` batched times, printing `"Running: batched [1/5]..."` etc.
- Compute stats for both, call `print_results`, return 0.

**CMake integration:**

Append to `tests/CMakeLists.txt` (after the `endif()` closing the C API tests section):

```cmake
# Benchmark executable (not part of test suite)
add_executable(quiver_benchmark
    benchmark/benchmark.cpp
)

target_link_libraries(quiver_benchmark
    PRIVATE
        quiver
        quiver_compiler_options
)

# Copy DLLs for benchmark
if(WIN32 AND BUILD_SHARED_LIBS)
    add_custom_command(TARGET quiver_benchmark POST_BUILD
        COMMAND ${CMAKE_COMMAND} -E copy_if_different
            $<TARGET_FILE:quiver>
            $<TARGET_FILE_DIR:quiver_benchmark>
    )
endif()
```

No `gtest_discover_tests` call. No GTest link. This is a plain main() executable.
  </action>
  <verify>
Build the project:
```bash
cmake -B build -DCMAKE_BUILD_TYPE=Debug -DQUIVER_BUILD_TESTS=ON -DQUIVER_BUILD_C_API=ON
cmake --build build --config Debug
```
Verify `build/bin/quiver_benchmark.exe` exists. Run the existing test suites to confirm no regression:
```bash
./build/bin/quiver_tests.exe
./build/bin/quiver_c_tests.exe
```
Run the benchmark with a reduced element count (modify source temporarily or just run as-is -- at 5000 elements it should complete within ~60 seconds):
```bash
./build/bin/quiver_benchmark.exe
```
Confirm output shows: banner with parameters, ASCII table with both variants, speedup ratio > 1x for batched.
  </verify>
  <done>
quiver_benchmark.exe builds, runs, and prints a clean ASCII table showing individual vs batched performance. Batched variant shows measurable speedup. Existing test suites pass without regression. Benchmark is NOT included in gtest_discover_tests.
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate benchmark into build-all.bat</name>
  <files>
    scripts/build-all.bat
  </files>
  <action>
The CMake build step in `build-all.bat` already builds all targets (including quiver_benchmark) via `cmake --build build --config %BUILD_TYPE%`. No changes needed to the build step itself.

Verify that `test-all.bat` does NOT reference `quiver_benchmark` -- it should not. If `test-all.bat` exists and already doesn't mention the benchmark, no changes needed there either.

The only change needed: update `build-all.bat` summary section to mention the benchmark was built. In the Summary section at the end, after the existing summary lines, add a line indicating the benchmark is available:

```
echo   Benchmark:    Built (run manually: build\bin\quiver_benchmark.exe)
```

Insert this line after `echo   Dart tests:   OK` and before the final `echo.`.

This communicates to the user that the benchmark was built but not run, consistent with the user's decision that build-all.bat builds it but test-all.bat does NOT run it.
  </action>
  <verify>
Run `scripts/build-all.bat` and verify:
1. Build completes successfully (benchmark is compiled alongside tests)
2. Summary output includes the benchmark line
3. The benchmark is NOT executed during the build/test run
Verify `scripts/test-all.bat` (if it exists) does not mention quiver_benchmark.
  </verify>
  <done>
build-all.bat builds the benchmark as part of the normal build and mentions it in the summary. The benchmark is never executed automatically by build-all.bat or test-all.bat.
  </done>
</task>

</tasks>

<verification>
1. `build/bin/quiver_benchmark.exe` exists after `cmake --build build --config Debug`
2. Running `quiver_benchmark.exe` prints a header banner with parameters (5000 elements, 10 TS rows/elem, collections.sql, 5 iterations)
3. Output shows an ASCII table with columns: Variant, Total (ms), Per-elem (ms), Ops/sec, Speedup
4. Individual variant row shows speedup "1.00x"
5. Batched variant row shows speedup > 1x (expected: significantly higher, likely 10x+ on file-based DB)
6. `quiver_tests.exe` and `quiver_c_tests.exe` continue to pass (no regression)
7. `build-all.bat` builds the benchmark but does not execute it
8. No `gtest_discover_tests(quiver_benchmark)` call in CMakeLists.txt
</verification>

<success_criteria>
- Benchmark executable builds and runs without errors
- ASCII table output matches user specification (all four metrics, header banner, clean formatting)
- Batched transaction variant is measurably faster than individual
- Benchmark is built by build-all.bat but NOT run by test-all.bat
- All existing tests pass without regression
</success_criteria>

<output>
After completion, create `.planning/phases/04-performance-benchmark/04-01-SUMMARY.md`
</output>
